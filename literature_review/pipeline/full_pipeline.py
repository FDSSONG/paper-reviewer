"""
ä¸€é”®å¼ç«¯åˆ°ç«¯æµæ°´çº¿ â€” ä» PDF åˆ°è¯„å®¡æŠ¥å‘Š

ç›´æ¥ä¸²è”ç°æœ‰ 4 ä¸ª pipelineï¼š
  Stage 1: mineru_pipeline          â†’ PDF â†’ Markdown
  Stage 2: literature_search_pipeline â†’ å…ƒæ•°æ® â†’ æŸ¥è¯¢ â†’ arXiv æ£€ç´¢
  Stage 3: ranking_and_summary_pipeline â†’ è¯„åˆ† â†’ Top-K â†’ æ‘˜è¦
  Stage 4: review_pipeline          â†’ è¯„å®¡æŠ¥å‘Šç”Ÿæˆ

ç”¨æ³•ï¼š
  python full_pipeline.py 2401.12345.pdf
  python full_pipeline.py 2401.12345.pdf --skip-mineru
  python full_pipeline.py 2401.12345.pdf --stage 3
"""

import sys
import time
import argparse
import logging
from pathlib import Path

# ç¡®ä¿ import è·¯å¾„æ­£ç¡®
PIPELINE_DIR = Path(__file__).parent.resolve()
sys.path.insert(0, str(PIPELINE_DIR.parent.parent))

# å¤ç”¨ç°æœ‰ pipeline
from literature_review.pipeline.mineru_pipeline import (
    main as mineru_main,
    apply_upload_url, put_upload_file, poll_until_done, persist_result,
    TOKEN as DEFAULT_TOKEN,
)
from literature_review.pipeline.literature_search_pipeline import run_literature_search
from literature_review.pipeline.ranking_and_summary_pipeline import run_ranking_and_summary
from literature_review.pipeline.review_pipeline import run_review_generation
from literature_review.logger import setup_logger, get_logger

logger = get_logger("full_pipeline")


def run_stage1(pdf_path: Path, paper_id: str, outputs_dir: Path,
               token: str = None, model_version: str = "vlm"):
    """
    Stage 1: PDF â†’ Markdown (MinerU)

    mineru_pipeline.main() ä½¿ç”¨ç¡¬ç¼–ç çš„å…¨å±€å˜é‡ï¼Œä¸æ–¹ä¾¿ä¼ å‚ï¼Œ
    å› æ­¤è¿™é‡Œç›´æ¥è°ƒç”¨å®ƒå†…éƒ¨çš„å‡½æ•°æ¥ç»„è£…æµç¨‹ã€‚
    """
    out_dir = outputs_dir / paper_id
    full_md = out_dir / "full.md"

    if full_md.exists():
        logger.info("â­ï¸  full.md å·²å­˜åœ¨ï¼Œè·³è¿‡ MinerU è§£æ")
        return full_md

    tk = token or DEFAULT_TOKEN

    logger.info("ğŸ“¤ ä¸Šä¼  PDF åˆ° MinerU...")
    batch_id, upload_url = apply_upload_url(tk, pdf_path, model_version)
    put_upload_file(pdf_path, upload_url)
    logger.info(f"âœ… ä¸Šä¼ å®Œæˆ, batch_id = {batch_id}")

    logger.info("â³ ç­‰å¾… MinerU è§£æ...")
    final_json = poll_until_done(tk, batch_id, timeout=300, interval=5)
    zip_url = final_json["data"]["extract_result"][0]["full_zip_url"]

    logger.info("ğŸ“¥ ä¸‹è½½å¹¶è§£å‹ç»“æœ...")
    persist_result(zip_url, out_dir, keep_zip=True, keep_meta=True)
    logger.info(f"âœ… å·²ä¿å­˜: {full_md}")
    return full_md


def run_full_pipeline(
    pdf_path: str,
    start_stage: int = 1,
    num_queries: int = 7,
    since_year: int = 2020,
    max_results_per_query: int = 20,
    top_k: int = 15,
    language: str = "chinese",
    skip_mineru: bool = False,
    mineru_token: str = None,
):
    """ä¸€é”®è¿è¡Œå®Œæ•´æµæ°´çº¿"""
    pdf_path = Path(pdf_path).resolve()
    paper_id = pdf_path.stem
    outputs_dir = PIPELINE_DIR / "outputs"
    results_dir = PIPELINE_DIR / "literature_search_results"

    total_start = time.time()

    logger.info("â•”" + "â•" * 68 + "â•—")
    logger.info("â•‘" + "  ğŸš€ å­¦æœ¯è®ºæ–‡ä¸€é”®è¯„å®¡æµæ°´çº¿".center(58) + "â•‘")
    logger.info("â•š" + "â•" * 68 + "â•")
    logger.info(f"PDF: {pdf_path} | è®ºæ–‡ ID: {paper_id} | èµ·å§‹é˜¶æ®µ: Stage {start_stage} | è¯­è¨€: {language} | Top-K: {top_k}")
    logger.info("â”€" * 70)

    # â”€â”€â”€â”€ Stage 1: PDF â†’ Markdown â”€â”€â”€â”€
    if start_stage <= 1:
        logger.info("\nâ–¶ Stage 1/4: PDF â†’ Markdown (MinerU)")
        logger.info("â”€" * 70)
        if skip_mineru:
            full_md = outputs_dir / paper_id / "full.md"
            if not full_md.exists():
                logger.error(f"--skip-mineru ä½† {full_md} ä¸å­˜åœ¨")
                sys.exit(1)
            logger.info("â­ï¸  è·³è¿‡ MinerUï¼ˆå·²æœ‰ full.mdï¼‰")
        else:
            if not pdf_path.exists():
                logger.error(f"PDF ä¸å­˜åœ¨: {pdf_path}")
                sys.exit(1)
            run_stage1(pdf_path, paper_id, outputs_dir, token=mineru_token)

    # â”€â”€â”€â”€ Stage 2: æ–‡çŒ®æ£€ç´¢ â”€â”€â”€â”€
    if start_stage <= 2:
        logger.info("\nâ–¶ Stage 2/4: å…ƒæ•°æ®æå– â†’ æŸ¥è¯¢ç”Ÿæˆ â†’ arXiv æ£€ç´¢")
        logger.info("â”€" * 70)
        run_literature_search(
            paper_id=paper_id,
            num_queries=num_queries,
            since_year=since_year,
            max_results_per_query=max_results_per_query,
            output_dir=str(results_dir),
        )

    # â”€â”€â”€â”€ Stage 3: è¯„åˆ† + æ‘˜è¦ â”€â”€â”€â”€
    if start_stage <= 3:
        logger.info("\nâ–¶ Stage 3/4: ç›¸å…³åº¦è¯„åˆ† â†’ Top-K ç­›é€‰ â†’ æ‘˜è¦ç”Ÿæˆ")
        logger.info("â”€" * 70)
        run_ranking_and_summary(
            paper_id=paper_id,
            top_k=top_k,
            language=language,
            input_dir=str(results_dir),
        )

    # â”€â”€â”€â”€ Stage 4: è¯„å®¡æŠ¥å‘Š â”€â”€â”€â”€
    if start_stage <= 4:
        logger.info("\nâ–¶ Stage 4/4: ç”Ÿæˆç»“æ„åŒ–è¯„å®¡æŠ¥å‘Š")
        logger.info("â”€" * 70)
        run_review_generation(
            paper_id=paper_id,
            language=language,
            input_dir=str(results_dir),
        )

    # â”€â”€â”€â”€ æ±‡æ€» â”€â”€â”€â”€
    elapsed = time.time() - total_start
    m, s = int(elapsed // 60), int(elapsed % 60)

    logger.info("â•" * 70)
    logger.info(f"âœ… å…¨éƒ¨å®Œæˆï¼æ€»è€—æ—¶ {m}åˆ†{s}ç§’")
    logger.info(f"ğŸ“ è¯„å®¡æŠ¥å‘Š: {results_dir / paper_id / f'review_report_{language}.md'}")
    logger.info("â•" * 70)


def main():
    parser = argparse.ArgumentParser(
        description='å­¦æœ¯è®ºæ–‡ä¸€é”®è¯„å®¡ â€” ä» PDF åˆ°è¯„å®¡æŠ¥å‘Š',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  python full_pipeline.py ../../2401.12345.pdf                    # å®Œæ•´æµç¨‹
  python full_pipeline.py ../../2401.12345.pdf --skip-mineru      # è·³è¿‡ PDF è§£æ
  python full_pipeline.py ../../2401.12345.pdf --stage 3          # ä» Stage 3 ç»­è·‘
  python full_pipeline.py ../../2401.12345.pdf -k 10 -l english   # è‡ªå®šä¹‰å‚æ•°
"""
    )

    parser.add_argument('pdf_path', help='PDF æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--stage', type=int, default=1, choices=[1, 2, 3, 4],
                        help='ä»ç¬¬å‡ é˜¶æ®µå¼€å§‹ï¼ˆé»˜è®¤: 1ï¼‰')
    parser.add_argument('-n', '--num-queries', type=int, default=7,
                        help='æ£€ç´¢æŸ¥è¯¢æ•°é‡ï¼ˆé»˜è®¤: 7ï¼‰')
    parser.add_argument('-y', '--since-year', type=int, default=2020,
                        help='èµ·å§‹å¹´ä»½ï¼ˆé»˜è®¤: 2020ï¼‰')
    parser.add_argument('-r', '--max-results', type=int, default=20,
                        help='æ¯æ¡æŸ¥è¯¢æœ€å¤§ç»“æœæ•°ï¼ˆé»˜è®¤: 20ï¼‰')
    parser.add_argument('-k', '--top-k', type=int, default=15,
                        help='é«˜ç›¸å…³åº¦è®ºæ–‡æ•°é‡ï¼ˆé»˜è®¤: 15ï¼‰')
    parser.add_argument('-l', '--language', choices=['chinese', 'english'],
                        default='chinese', help='è¾“å‡ºè¯­è¨€ï¼ˆé»˜è®¤: chineseï¼‰')
    parser.add_argument('--skip-mineru', action='store_true',
                        help='è·³è¿‡ MinerU è§£æï¼ˆå·²æœ‰ full.mdï¼‰')
    parser.add_argument('--mineru-token', default=None,
                        help='MinerU API Token')

    args = parser.parse_args()

    # åˆå§‹åŒ–æ—¥å¿—ç³»ç»Ÿ
    outputs_dir = PIPELINE_DIR / "outputs"
    log_dir = outputs_dir / "logs"
    setup_logger(name="literature_review", log_dir=log_dir, level=logging.INFO)

    try:
        run_full_pipeline(
            pdf_path=args.pdf_path,
            start_stage=args.stage,
            num_queries=args.num_queries,
            since_year=args.since_year,
            max_results_per_query=args.max_results,
            top_k=args.top_k,
            language=args.language,
            skip_mineru=args.skip_mineru,
            mineru_token=args.mineru_token,
        )
    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­")
        sys.exit(130)
    except Exception as e:
        logger.exception(f"å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == '__main__':
    main()
