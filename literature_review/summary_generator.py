#!/usr/bin/env python3
"""
æ‘˜è¦ç”Ÿæˆæ¨¡å—
ä¸ºé«˜ç›¸å…³åº¦è®ºæ–‡ç”Ÿæˆè¯¦ç»†å¯¹æ¯”æ‘˜è¦ï¼Œä¸ºä½ç›¸å…³åº¦è®ºæ–‡ä½¿ç”¨åŸæ‘˜è¦
"""
import sys
import os
from pathlib import Path
from typing import Dict, Optional
from literature_review.logger import get_logger

logger = get_logger("summary_generator")

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from deepseek_api import DeepSeekAPI


class SummaryGenerator:
    """æ‘˜è¦ç”Ÿæˆå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.api = DeepSeekAPI()
    
    def generate_detailed_summary(
        self,
        source_paper: Dict,
        candidate_paper: Dict,
        candidate_markdown: str,
        language: str = "chinese"
    ) -> str:
        """
        ä¸ºé«˜ç›¸å…³åº¦è®ºæ–‡ç”Ÿæˆè¯¦ç»†å¯¹æ¯”æ‘˜è¦
        
        Args:
            source_paper: æºè®ºæ–‡å…ƒæ•°æ®
            candidate_paper: å€™é€‰è®ºæ–‡å…ƒæ•°æ®
            candidate_markdown: å€™é€‰è®ºæ–‡çš„å®Œæ•´ Markdown å†…å®¹
            language: è¾“å‡ºè¯­è¨€ ('chinese' æˆ– 'english')
        
        Returns:
            è¯¦ç»†æ‘˜è¦æ–‡æœ¬ï¼ˆ200-300è¯ï¼‰
        """
        logger.info(f"ğŸ¤– ç”Ÿæˆè¯¦ç»†æ‘˜è¦: {candidate_paper['title'][:60]}...")
        
        # æ„å»ºæç¤ºè¯
        if language == "chinese":
            prompt = self._build_chinese_prompt(
                source_paper, candidate_paper, candidate_markdown
            )
        else:
            prompt = self._build_english_prompt(
                source_paper, candidate_paper, candidate_markdown
            )
        
        try:
            summary = self.api.simple_ask(prompt, temperature=0.7)
            logger.info(f"âœ… æ‘˜è¦ç”ŸæˆæˆåŠŸ ({len(summary)} å­—ç¬¦)")
            return summary
        
        except Exception as e:
            logger.error(f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {e}")
            # é™çº§ï¼šè¿”å›åŸæ‘˜è¦
            return candidate_paper.get('abstract', 'æ— æ‘˜è¦')
    
    def _build_chinese_prompt(
        self,
        source_paper: Dict,
        candidate_paper: Dict,
        candidate_markdown: str
    ) -> str:
        """æ„å»ºä¸­æ–‡æç¤ºè¯"""
        source_title = source_paper.get('title', 'æœªçŸ¥')
        source_abstract = source_paper.get('abstract', 'æ— æ‘˜è¦')
        
        candidate_title = candidate_paper['title']
        candidate_abstract = candidate_paper.get('abstract', 'æ— æ‘˜è¦')
        
        # é™åˆ¶ Markdown é•¿åº¦ä»¥èŠ‚çœ token
        max_md_len = 15000  # çº¦ 4000 tokens
        if len(candidate_markdown) > max_md_len:
            candidate_markdown = candidate_markdown[:max_md_len] + "\n\n... (å†…å®¹è¿‡é•¿å·²æˆªæ–­)"
        
        prompt = f"""ä½œä¸ºå­¦æœ¯ç ”ç©¶åŠ©æ‰‹ï¼Œè¯·å¯¹æ¯”åˆ†æä»¥ä¸‹ä¸¤ç¯‡è®ºæ–‡ï¼Œå†™ä¸€ç¯‡200-300è¯çš„ä¸­æ–‡è¯¦ç»†æ‘˜è¦ã€‚

ã€æºè®ºæ–‡ï¼ˆå¾…ç ”ç©¶ï¼‰ã€‘
æ ‡é¢˜ï¼š{source_title}
æ‘˜è¦ï¼š{source_abstract}

ã€å€™é€‰è®ºæ–‡ï¼ˆç›¸å…³æ–‡çŒ®ï¼‰ã€‘
æ ‡é¢˜ï¼š{candidate_title}
æ‘˜è¦ï¼š{candidate_abstract}

ã€å€™é€‰è®ºæ–‡å®Œæ•´å†…å®¹ã€‘
{candidate_markdown}

---

è¯·ä»ä»¥ä¸‹ä¸‰ä¸ªç„¦ç‚¹è¿›è¡Œå¯¹æ¯”åˆ†æï¼š

1. **æ–¹æ³•å¯¹æ¯”**ï¼š
   - ä¸¤ç¯‡è®ºæ–‡ä½¿ç”¨çš„æ ¸å¿ƒæŠ€æœ¯æ–¹æ³•æœ‰ä½•å¼‚åŒï¼Ÿ
   - å€™é€‰è®ºæ–‡çš„æ–¹æ³•æ˜¯å¦å¯¹æºè®ºæ–‡æœ‰å€Ÿé‰´æˆ–æ”¹è¿›ï¼Ÿ
   - æ˜¯å¦é‡‡ç”¨äº†ä¸åŒçš„æŠ€æœ¯è·¯çº¿ï¼Ÿ

2. **å®éªŒå·®å¼‚**ï¼š
   - å®éªŒè®¾ç½®ï¼ˆæ•°æ®é›†ã€baselineã€è¯„ä¼°æŒ‡æ ‡ï¼‰æœ‰ä½•ä¸åŒï¼Ÿ
   - å®éªŒç»“æœçš„å¯¹æ¯”å¦‚ä½•ï¼Ÿå“ªç¯‡è¡¨ç°æ›´å¥½ï¼Ÿ
   - æ˜¯å¦åœ¨ç›¸åŒæˆ–ä¸åŒçš„åº”ç”¨åœºæ™¯ä¸‹éªŒè¯ï¼Ÿ

3. **ç»“è®ºå¼‚åŒ**ï¼š
   - ä¸¤ç¯‡è®ºæ–‡çš„ä¸»è¦ç ”ç©¶ç»“è®ºæ˜¯å¦ä¸€è‡´ï¼Ÿ
   - æ˜¯å¦å­˜åœ¨äº’è¡¥å…³ç³»æˆ–çŸ›ç›¾ä¹‹å¤„ï¼Ÿ
   - å€™é€‰è®ºæ–‡å¯¹æºè®ºæ–‡çš„ç ”ç©¶æœ‰ä½•å¯å‘æˆ–è¡¥å……ï¼Ÿ

**è¦æ±‚**ï¼š
- 200-300è¯çš„ä¸­æ–‡
- å®¢è§‚ã€å‡†ç¡®ã€ä¸“ä¸š
- é‡ç‚¹çªå‡ºä¸‰ä¸ªç„¦ç‚¹çš„å¯¹æ¯”åˆ†æ
- ä¸è¦ç®€å•å¤è¿°è®ºæ–‡å†…å®¹ï¼Œè¦æ·±å…¥åˆ†æå¼‚åŒ
"""
        return prompt
    
    def _build_english_prompt(
        self,
        source_paper: Dict,
        candidate_paper: Dict,
        candidate_markdown: str
    ) -> str:
        """æ„å»ºè‹±æ–‡æç¤ºè¯"""
        source_title = source_paper.get('title', 'Unknown')
        source_abstract = source_paper.get('abstract', 'No abstract')
        
        candidate_title = candidate_paper['title']
        candidate_abstract = candidate_paper.get('abstract', 'No abstract')
        
        # é™åˆ¶ Markdown é•¿åº¦
        max_md_len = 15000
        if len(candidate_markdown) > max_md_len:
            candidate_markdown = candidate_markdown[:max_md_len] + "\n\n... (content truncated)"
        
        prompt = f"""As an academic research assistant, please write a detailed 200-300 word comparative summary of the following two papers.

ã€Source Paper (Under Study)ã€‘
Title: {source_title}
Abstract: {source_abstract}

ã€Candidate Paper (Related Literature)ã€‘
Title: {candidate_title}
Abstract: {candidate_abstract}

ã€Full Content of Candidate Paperã€‘
{candidate_markdown}

---

Please analyze and compare from the following three perspectives:

1. **Methodology Comparison**:
   - What are the similarities and differences in the core technical methods used?
   - Does the candidate paper build upon or improve the source paper's methods?
   - Are different technical approaches employed?

2. **Experimental Differences**:
   - How do the experimental setups (datasets, baselines, evaluation metrics) differ?
   - How do the experimental results compare? Which performs better?
   - Are they validated in the same or different application scenarios?

3. **Conclusion Alignment**:
   - Are the main research conclusions consistent between the two papers?
   - Is there a complementary relationship or contradictions?
   - What insights or supplements does the candidate paper provide for the source paper?

**Requirements**:
- 200-300 words in English
- Objective, accurate, and professional
- Focus on comparative analysis across the three perspectives
- Provide deep analysis of similarities and differences, not just summary
"""
        return prompt
    
    def use_original_abstract(self, paper: Dict) -> str:
        """
        ä½¿ç”¨åŸå§‹æ‘˜è¦ï¼ˆä½ç›¸å…³åº¦è®ºæ–‡ï¼‰
        
        Args:
            paper: è®ºæ–‡å…ƒæ•°æ®
        
        Returns:
            åŸå§‹æ‘˜è¦
        """
        abstract = paper.get('abstract', 'æ— æ‘˜è¦')
        logger.info(f"ğŸ“„ ä½¿ç”¨åŸæ‘˜è¦: {paper['title'][:60]}...")
        return abstract
    
    def save_summary(
        self,
        summary: str,
        output_path: Path,
        metadata: Dict = None
    ):
        """
        ä¿å­˜æ‘˜è¦åˆ°æ–‡ä»¶
        
        Args:
            summary: æ‘˜è¦å†…å®¹
            output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
            metadata: é¢å¤–çš„å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
        """
        output_path.parent.mkdir(parents=True, exist_ok=True)
        
        content = ""
        
        # æ·»åŠ å…ƒæ•°æ®å¤´éƒ¨
        if metadata:
            content += "---\n"
            content += f"æ ‡é¢˜: {metadata.get('title', '')}\n"
            content += f"ä½œè€…: {', '.join(metadata.get('authors', [])[:5])}\n"
            content += f"å‘å¸ƒæ—¥æœŸ: {metadata.get('published', '')}\n"
            content += f"arXiv ID: {metadata.get('arxiv_id', '')}\n"
            content += f"PDF: {metadata.get('pdf_url', '')}\n"
            content += "---\n\n"
        
        # æ·»åŠ æ‘˜è¦å†…å®¹
        content += "# å¯¹æ¯”æ‘˜è¦\n\n"
        content += summary
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(content)
        
        logger.info(f"âœ… æ‘˜è¦å·²ä¿å­˜: {output_path}")


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    generator = SummaryGenerator()
    
    source = {
        'title': 'Attention Is All You Need',
        'abstract': 'We propose a new simple network architecture, the Transformer.'
    }
    
    candidate = {
        'arxiv_id': '1810.04805',
        'title': 'BERT: Pre-training of Deep Bidirectional Transformers',
        'abstract': 'We introduce BERT, which stands for Bidirectional Encoder Representations from Transformers.',
        'authors': ['Jacob Devlin', 'Ming-Wei Chang'],
        'published': '2018-10-11',
        'pdf_url': 'https://arxiv.org/pdf/1810.04805'
    }
    
    candidate_md = """
# BERT: Pre-training of Deep Bidirectional Transformers

## Abstract
We introduce a new language representation model called BERT...

## 1. Introduction
Language model pre-training has been shown to be effective...

## 2. Related Work
There is a long history of pre-training general language representations...

## 3. BERT
We introduce BERT and its detailed implementation...
"""
    
    print("=" * 70)
    print("æ‘˜è¦ç”Ÿæˆæµ‹è¯•")
    print("=" * 70)
    
    # ç”Ÿæˆè¯¦ç»†æ‘˜è¦
    summary = generator.generate_detailed_summary(
        source, candidate, candidate_md, language="chinese"
    )
    
    print("\nç”Ÿæˆçš„æ‘˜è¦:")
    print("-" * 70)
    print(summary)
