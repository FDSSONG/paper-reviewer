#!/usr/bin/env python3
"""
æœç´¢æŸ¥è¯¢ç”Ÿæˆæ¨¡å— - ç±»å°è£…ç‰ˆæœ¬
ä½¿ç”¨ DeepSeek API ä»è®ºæ–‡å†…å®¹ç”Ÿæˆå¤šä¸ªæœç´¢æŸ¥è¯¢
"""
import sys
import os
from typing import List, Dict
from literature_review.logger import get_logger

logger = get_logger("query_generator")

# æ·»åŠ çˆ¶ç›®å½•åˆ°è·¯å¾„ä»¥å¯¼å…¥ deepseek_api
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from deepseek_api import DeepSeekAPI


class QueryGenerator:
    """æŸ¥è¯¢ç”Ÿæˆå™¨ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–ç”Ÿæˆå™¨"""
        self.api = DeepSeekAPI()
    
    def generate_queries(
        self,
        markdown_text: str = None,
        metadata: Dict = None,
        num_queries: int = 7
    ) -> List[str]:
        """
        ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼ˆç®€åŒ–ç‰ˆï¼Œåªè¿”å›æŸ¥è¯¢å­—ç¬¦ä¸²åˆ—è¡¨ï¼‰
        
        Args:
            markdown_text: Markdown æ–‡æœ¬ï¼ˆå¯é€‰ï¼‰
            metadata: å…ƒæ•°æ®å­—å…¸ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨å…¶ä¸­çš„ä¿¡æ¯ï¼‰
            num_queries: ç”Ÿæˆçš„æŸ¥è¯¢æ•°é‡
        
        Returns:
            ["query1", "query2", ...]
        """
        # ä» metadata æå–ä¿¡æ¯
        if metadata:
            title = metadata.get('title', '')
            abstract = metadata.get('abstract', '')
            sections = metadata.get('sections', [])
        else:
            title = ''
            abstract = ''
            sections = []
        
        # è°ƒç”¨å®Œæ•´çš„ç”Ÿæˆå‡½æ•°
        queries_with_meta = self.generate_search_queries(
            title=title,
            abstract=abstract,
            sections=sections,
            num_queries=num_queries
        )
        
        # åªè¿”å›æŸ¥è¯¢å­—ç¬¦ä¸²
        return [q['query'] for q in queries_with_meta]
    
    def generate_search_queries(
        self,
        title: str,
        abstract: str,
        sections: List[Dict],
        num_queries: int = 7
    ) -> List[Dict[str, str]]:
        """
        ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼ˆå®Œæ•´ç‰ˆï¼ŒåŒ…å«å…ƒä¿¡æ¯ï¼‰
        
        Args:
            title: è®ºæ–‡æ ‡é¢˜
            abstract: æ‘˜è¦
            sections: ç« èŠ‚åˆ—è¡¨
            num_queries: ç”Ÿæˆçš„æŸ¥è¯¢æ•°é‡ï¼ˆé»˜è®¤7æ¡ï¼‰
        
        Returns:
            [
                {
                    "query": "deep learning transformers attention mechanism",
                    "perspective": "technical_approach",
                    "description": "ç›¸ä¼¼æŠ€æœ¯è·¯çº¿"
                },
                ...
            ]
        """
        logger.info(f"ğŸ” ç”Ÿæˆ {num_queries} æ¡æœç´¢æŸ¥è¯¢...")
        
        # å‡†å¤‡è®ºæ–‡æ¦‚è¦
        section_titles = [s['title'] for s in sections[:10]]  # åªå–å‰10ä¸ªç« èŠ‚æ ‡é¢˜
        sections_text = ", ".join(section_titles)
        
        # æ„å»ºæç¤ºè¯
        prompt = f"""ä½ æ˜¯ä¸€ä½å­¦æœ¯ç ”ç©¶åŠ©æ‰‹ã€‚è¯·é˜…è¯»ä»¥ä¸‹è®ºæ–‡ä¿¡æ¯ï¼Œç”Ÿæˆ {num_queries} æ¡è‹±æ–‡æœç´¢æŸ¥è¯¢ï¼Œç”¨äºåœ¨ arXiv ä¸Šæ£€ç´¢ç›¸å…³è®ºæ–‡ã€‚

è®ºæ–‡æ ‡é¢˜ï¼š{title}

æ‘˜è¦ï¼š{abstract if abstract else "æ— æ‘˜è¦"}

ä¸»è¦ç« èŠ‚ï¼š{sections_text}

è¯·ä»ä»¥ä¸‹ä¸åŒè§†è§’ç”Ÿæˆæœç´¢æŸ¥è¯¢ï¼š
1. ç›¸åŒç ”ç©¶é—®é¢˜ï¼ˆ2æ¡ï¼‰- ç ”ç©¶åŒä¸€é—®é¢˜çš„å…¶ä»–æ–¹æ³•
2. ç›¸ä¼¼æŠ€æœ¯è·¯çº¿ï¼ˆ2æ¡ï¼‰- ä½¿ç”¨ç›¸åŒæˆ–ç±»ä¼¼æŠ€æœ¯çš„è®ºæ–‡
3. ç›¸å…³æ ‡å‡†/åŸºå‡†ï¼ˆ1æ¡ï¼‰- ç›¸å…³çš„è¯„ä¼°æ ‡å‡†ã€æ•°æ®é›†æˆ–åŸºå‡†
4. æ›¿ä»£æ–¹æ³•ï¼ˆ1æ¡ï¼‰- è§£å†³åŒä¸€é—®é¢˜çš„ä¸åŒæ–¹æ³•
5. åº”ç”¨é¢†åŸŸæ‰©å±•ï¼ˆ1æ¡ï¼‰- åœ¨ç›¸å…³é¢†åŸŸçš„åº”ç”¨

è¦æ±‚ï¼š
- æ¯æ¡æŸ¥è¯¢ä¸º3-6ä¸ªå…³é”®è¯çš„ç»„åˆï¼Œç”¨ç©ºæ ¼åˆ†éš”
- ä½¿ç”¨è‹±æ–‡ï¼Œé€‚åˆ arXiv æœç´¢
- é¿å…è¿‡äºå®½æ³›æˆ–è¿‡äºå…·ä½“
- ä¸è¦åŒ…å«å¼•å·ã€æ‹¬å·ç­‰ç‰¹æ®Šç¬¦å·

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "queries": [
    {{
      "query": "å…³é”®è¯ç»„åˆ",
      "perspective": "research_problem|technical_approach|standard|alternative|application",
      "description": "ä¸­æ–‡æè¿°è¿™æ¡æŸ¥è¯¢çš„ç›®çš„"
    }}
  ]
}}"""
        
        try:
            result = self.api.simple_ask_json(prompt, temperature=0.7)
            
            queries = result.get('queries', [])
            
            # éªŒè¯å’Œæ ¼å¼åŒ–
            formatted_queries = []
            for q in queries[:num_queries]:
                if 'query' in q and 'perspective' in q:
                    formatted_queries.append({
                        'query': q['query'].strip(),
                        'perspective': q.get('perspective', 'unknown'),
                        'description': q.get('description', '')
                    })
            
            logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(formatted_queries)} æ¡æŸ¥è¯¢")
            for i, q in enumerate(formatted_queries, 1):
                logger.info(f"  {i}. [{q['perspective']}] {q['query']}")
            
            return formatted_queries
        
        except Exception as e:
            logger.error(f"ç”ŸæˆæŸ¥è¯¢å¤±è´¥: {e}")
            # è¿”å›é™çº§æŸ¥è¯¢ï¼ˆåŸºäºæ ‡é¢˜çš„ç®€å•æŸ¥è¯¢ï¼‰
            logger.warning("ä½¿ç”¨é™çº§æ–¹æ¡ˆï¼šåŸºäºæ ‡é¢˜ç”ŸæˆåŸºç¡€æŸ¥è¯¢")
            return [{
                'query': title.lower().replace(':', '').replace('-', ' ')[:100],
                'perspective': 'title_based',
                'description': 'åŸºäºæ ‡é¢˜çš„åŸºç¡€æŸ¥è¯¢'
            }]


# ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™åŸæœ‰çš„å‡½æ•°æ¥å£
def generate_queries_from_metadata(metadata: Dict, num_queries: int = 7) -> List[Dict[str, str]]:
    """å‘åå…¼å®¹çš„å‡½æ•°æ¥å£"""
    generator = QueryGenerator()
    return generator.generate_search_queries(
        title=metadata.get('title', ''),
        abstract=metadata.get('abstract', ''),
        sections=metadata.get('sections', []),
        num_queries=num_queries
    )


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    import json
    
    # ç¤ºä¾‹å…ƒæ•°æ®
    sample_metadata = {
        "title": "Attention Is All You Need: Transformers for Natural Language Processing",
        "abstract": "This paper introduces the Transformer architecture, a novel neural network design that relies entirely on attention mechanisms, dispensing with recurrence and convolutions. We show that Transformers achieve state-of-the-art results on machine translation tasks while being more parallelizable and requiring significantly less time to train.",
        "sections": [
            {"title": "Introduction", "level": 1},
            {"title": "Background", "level": 1},
            {"title": "Model Architecture", "level": 1},
            {"title": "Self-Attention", "level": 2},
            {"title": "Multi-Head Attention", "level": 2},
            {"title": "Experiments", "level": 1},
            {"title": "Results", "level": 1},
            {"title": "Conclusion", "level": 1},
        ]
    }
    
    print("=" * 60)
    print("æŸ¥è¯¢ç”Ÿæˆæµ‹è¯•")
    print("=" * 60)
    
    generator = QueryGenerator()
    queries = generator.generate_queries(metadata=sample_metadata, num_queries=7)
    
    print("\nç”Ÿæˆçš„æŸ¥è¯¢ï¼š")
    print(json.dumps(queries, ensure_ascii=False, indent=2))
