#!/usr/bin/env python3
"""
æ ¼å¼æ ¡éªŒæ¨¡å—
éªŒè¯è®ºæ–‡æ ¼å¼çš„å®Œæ•´æ€§å’Œè§„èŒƒæ€§
"""
from typing import Dict, List
import json


def validate_paper_format(metadata: Dict) -> Dict:
    """
    éªŒè¯è®ºæ–‡æ ¼å¼å®Œæ•´æ€§
    
    Args:
        metadata: ä»metadata_extractoræå–çš„å…ƒæ•°æ®
    
    Returns:
        {
            "valid": bool,  # æ˜¯å¦é€šè¿‡æ ¡éªŒ
            "score": float,  # å®Œæ•´æ€§è¯„åˆ† (0-100)
            "issues": [...],  # ä¸¥é‡é—®é¢˜åˆ—è¡¨
            "warnings": [...],  # è­¦å‘Šåˆ—è¡¨
            "suggestions": [...]  # æ”¹è¿›å»ºè®®
        }
    """
    issues = []
    warnings = []
    suggestions = []
    score = 100.0
    
    # 1. æ£€æŸ¥æ ‡é¢˜
    if not metadata.get('title'):
        issues.append("âŒ ç¼ºå°‘è®ºæ–‡æ ‡é¢˜")
        score -= 20
    elif len(metadata.get('title', '')) < 10:
        warnings.append("âš ï¸  æ ‡é¢˜è¿‡çŸ­ï¼ˆå°‘äº10å­—ç¬¦ï¼‰")
        score -= 5
    
    # 2. æ£€æŸ¥ä½œè€…
    authors = metadata.get('authors', [])
    if not authors:
        issues.append("âŒ ç¼ºå°‘ä½œè€…ä¿¡æ¯")
        score -= 15
    elif len(authors) > 20:
        warnings.append(f"âš ï¸  ä½œè€…æ•°é‡å¼‚å¸¸å¤šï¼ˆ{len(authors)}äººï¼‰")
        score -= 2
    
    # 3. æ£€æŸ¥æ‘˜è¦
    abstract = metadata.get('abstract', '')
    if not abstract:
        issues.append("âŒ ç¼ºå°‘æ‘˜è¦")
        score -= 20
    elif len(abstract) < 100:
        warnings.append("âš ï¸  æ‘˜è¦è¿‡çŸ­ï¼ˆå°‘äº100å­—ç¬¦ï¼‰")
        score -= 5
    elif len(abstract) > 3000:
        warnings.append("âš ï¸  æ‘˜è¦è¿‡é•¿ï¼ˆè¶…è¿‡3000å­—ç¬¦ï¼‰")
        score -= 3
    
    # 4. æ£€æŸ¥ç« èŠ‚ç»“æ„
    sections = metadata.get('sections', [])
    if not sections:
        issues.append("âŒ æœªè¯†åˆ«åˆ°ç« èŠ‚ç»“æ„")
        score -= 25
    else:
        # æå–ç« èŠ‚åç§°ï¼ˆè½¬å°å†™ï¼‰
        section_names = [s.get('name', '').lower() for s in sections]
        
        # å¿…éœ€ç« èŠ‚
        required_sections = {
            'introduction': ['introduction', 'intro'],
            'method': ['method', 'methodology', 'approach'],
            'results': ['results', 'experiments', 'experimental results', 'evaluation'],
            'conclusion': ['conclusion', 'conclusions', 'summary']
        }
        
        missing_sections = []
        for section_type, keywords in required_sections.items():
            found = any(
                any(keyword in name for keyword in keywords)
                for name in section_names
            )
            if not found:
                missing_sections.append(section_type.capitalize())
        
        if missing_sections:
            warnings.append(f"âš ï¸  ç¼ºå°‘æ¨èç« èŠ‚: {', '.join(missing_sections)}")
            score -= len(missing_sections) * 3
        
        # ç›¸å…³å·¥ä½œç« èŠ‚ï¼ˆå¯é€‰ä½†æ¨èï¼‰
        has_related_work = any(
            'related' in name or 'background' in name or 'literature' in name
            for name in section_names
        )
        if not has_related_work:
            suggestions.append("ğŸ’¡ å»ºè®®æ·»åŠ  Related Work æˆ– Background ç« èŠ‚")
    
    # 5. æ£€æŸ¥å…³é”®è¯
    keywords = metadata.get('keywords', [])
    if not keywords:
        warnings.append("âš ï¸  ç¼ºå°‘å…³é”®è¯")
        score -= 3
    elif len(keywords) < 3:
        suggestions.append("ğŸ’¡ å»ºè®®æ·»åŠ æ›´å¤šå…³é”®è¯ï¼ˆè‡³å°‘3-5ä¸ªï¼‰")
    
    # 6. æ£€æŸ¥å‘è¡¨å¹´ä»½
    if not metadata.get('year'):
        suggestions.append("ğŸ’¡ æœªè¯†åˆ«åˆ°å‘è¡¨å¹´ä»½")
    
    # ç¡®ä¿åˆ†æ•°ä¸ä½äº0
    score = max(0, score)
    
    # åˆ¤æ–­æ˜¯å¦é€šè¿‡
    valid = len(issues) == 0 and score >= 60
    
    return {
        "valid": valid,
        "score": round(score, 1),
        "issues": issues,
        "warnings": warnings,
        "suggestions": suggestions,
        "details": {
            "has_title": bool(metadata.get('title')),
            "has_authors": bool(metadata.get('authors')),
            "has_abstract": bool(metadata.get('abstract')),
            "section_count": len(sections),
            "keyword_count": len(keywords),
            "has_year": bool(metadata.get('year'))
        }
    }


def print_validation_report(validation_result: Dict):
    """
    æ‰“å°æ ¼å¼åŒ–çš„æ ¡éªŒæŠ¥å‘Š
    
    Args:
        validation_result: validate_paper_formatçš„è¿”å›ç»“æœ
    """
    print("=" * 60)
    print("ğŸ“‹ è®ºæ–‡æ ¼å¼æ ¡éªŒæŠ¥å‘Š")
    print("=" * 60)
    
    # æ€»ä½“çŠ¶æ€
    status = "âœ… é€šè¿‡" if validation_result['valid'] else "âŒ æœªé€šè¿‡"
    score = validation_result['score']
    print(f"\nçŠ¶æ€: {status}")
    print(f"å®Œæ•´æ€§è¯„åˆ†: {score}/100")
    
    # è¯¦ç»†ä¿¡æ¯
    details = validation_result['details']
    print(f"\nè¯¦ç»†ä¿¡æ¯:")
    print(f"  - æ ‡é¢˜: {'âœ“' if details['has_title'] else 'âœ—'}")
    print(f"  - ä½œè€…: {'âœ“' if details['has_authors'] else 'âœ—'}")
    print(f"  - æ‘˜è¦: {'âœ“' if details['has_abstract'] else 'âœ—'}")
    print(f"  - ç« èŠ‚æ•°: {details['section_count']}")
    print(f"  - å…³é”®è¯æ•°: {details['keyword_count']}")
    print(f"  - å¹´ä»½: {'âœ“' if details['has_year'] else 'âœ—'}")
    
    # é—®é¢˜
    issues = validation_result['issues']
    if issues:
        print(f"\nä¸¥é‡é—®é¢˜ ({len(issues)}):")
        for issue in issues:
            print(f"  {issue}")
    
    # è­¦å‘Š
    warnings = validation_result['warnings']
    if warnings:
        print(f"\nè­¦å‘Š ({len(warnings)}):")
        for warning in warnings:
            print(f"  {warning}")
    
    # å»ºè®®
    suggestions = validation_result['suggestions']
    if suggestions:
        print(f"\næ”¹è¿›å»ºè®® ({len(suggestions)}):")
        for suggestion in suggestions:
            print(f"  {suggestion}")
    
    print("=" * 60)


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python format_validator.py <metadata_json_file>")
        sys.exit(1)
    
    metadata_file = sys.argv[1]
    
    # è¯»å–å…ƒæ•°æ®
    try:
        with open(metadata_file, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
    except Exception as e:
        print(f"âŒ è¯»å–å…ƒæ•°æ®æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)
    
    # æ‰§è¡Œæ ¡éªŒ
    validation_result = validate_paper_format(metadata)
    
    # æ‰“å°æŠ¥å‘Š
    print_validation_report(validation_result)
    
    # ä¿å­˜ç»“æœ
    output_file = metadata_file.replace('.json', '_validation.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(validation_result, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… æ ¡éªŒç»“æœå·²ä¿å­˜è‡³: {output_file}")
