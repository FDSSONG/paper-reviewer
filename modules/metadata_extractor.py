#!/usr/bin/env python3
"""
å…ƒæ•°æ®æå–æ¨¡å—
ä½¿ç”¨DeepSeekä»è®ºæ–‡Markdownä¸­æå–å…ƒæ•°æ®
"""
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from deepseek_api import DeepSeekAPI
from typing import Dict, List, Optional
import json


def extract_metadata(markdown_text: str, 
                     max_length: int = 20000) -> Dict:
    """
    ä»Markdownæ–‡æœ¬ä¸­æå–è®ºæ–‡å…ƒæ•°æ®
    
    Args:
        markdown_text: è®ºæ–‡çš„Markdownæ–‡æœ¬
        max_length: æœ€å¤§å¤„ç†é•¿åº¦ï¼ˆå­—ç¬¦æ•°ï¼‰
    
    Returns:
        {
            "title": "è®ºæ–‡æ ‡é¢˜",
            "authors": ["ä½œè€…1", "ä½œè€…2"],
            "abstract": "æ‘˜è¦",
            "sections": [
                {"name": "Sectionåç§°", "level": 1, "content_preview": "å‰100å­—"},
                ...
            ],
            "keywords": ["å…³é”®è¯1", "å…³é”®è¯2"],
            "year": "å‘è¡¨å¹´ä»½"
        }
    """
    api = DeepSeekAPI()
    
    # æˆªæ–­æ–‡æœ¬ï¼ˆä¿ç•™å¼€å¤´éƒ¨åˆ†ï¼Œé€šå¸¸åŒ…å«æ ‡é¢˜ã€ä½œè€…ã€æ‘˜è¦ï¼‰
    text_to_analyze = markdown_text[:max_length]
    
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªå­¦æœ¯è®ºæ–‡åˆ†æä¸“å®¶ã€‚è¯·ä»ä»¥ä¸‹è®ºæ–‡ä¸­æå–å…ƒæ•°æ®ã€‚

è¯·ä»¥JSONæ ¼å¼è¿”å›ï¼ŒåŒ…å«ä»¥ä¸‹å­—æ®µï¼š
- title: è®ºæ–‡æ ‡é¢˜ï¼ˆå­—ç¬¦ä¸²ï¼‰
- authors: ä½œè€…åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼‰
- abstract: æ‘˜è¦ï¼ˆå­—ç¬¦ä¸²ï¼Œæå–å®Œæ•´æ‘˜è¦ï¼‰
- sections: ç« èŠ‚åˆ—è¡¨ï¼ˆå¯¹è±¡æ•°ç»„ï¼‰ï¼Œæ¯ä¸ªå¯¹è±¡åŒ…å«ï¼š
  - name: ç« èŠ‚åç§°
  - level: å±‚çº§ï¼ˆ1ä¸ºä¸€çº§æ ‡é¢˜ï¼Œ2ä¸ºäºŒçº§ï¼‰
  - content_preview: è¯¥ç« èŠ‚çš„å‰100å­—
- keywords: å…³é”®è¯åˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²æ•°ç»„ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä¸ºç©ºæ•°ç»„ï¼‰
- year: å‘è¡¨å¹´ä»½ï¼ˆå­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ³•ç¡®å®šåˆ™ä¸ºnullï¼‰

æ³¨æ„ï¼š
1. æ ‡é¢˜é€šå¸¸åœ¨è®ºæ–‡å¼€å¤´ï¼Œå¯èƒ½å…¨å¤§å†™æˆ–é¦–å­—æ¯å¤§å†™
2. ä½œè€…é€šå¸¸åœ¨æ ‡é¢˜ä¸‹æ–¹
3. æ‘˜è¦é€šå¸¸æœ‰"Abstract"æ ‡é¢˜
4. ä¸»è¦ç« èŠ‚åŒ…æ‹¬ï¼šIntroduction, Related Work, Method/Methodology, Experiments/Results, Conclusionç­‰
5. å¦‚æœæŸäº›å­—æ®µæ— æ³•æå–ï¼Œè®¾ä¸ºnullæˆ–ç©ºæ•°ç»„

è®ºæ–‡å†…å®¹ï¼ˆå·²æˆªå–å‰{max_length}å­—ç¬¦ï¼‰ï¼š

{text_to_analyze}

è¯·ä¸¥æ ¼è¿”å›JSONæ ¼å¼ã€‚
"""
    
    print("ğŸ” æ­£åœ¨æå–å…ƒæ•°æ®...")
    
    try:
        result = api.simple_ask_json(prompt, temperature=0.3)
        
        # éªŒè¯å¿…éœ€å­—æ®µ
        if not result.get('title'):
            print("âš ï¸  è­¦å‘Š: æœªæå–åˆ°æ ‡é¢˜")
        if not result.get('authors'):
            print("âš ï¸  è­¦å‘Š: æœªæå–åˆ°ä½œè€…")
        if not result.get('sections'):
            print("âš ï¸  è­¦å‘Š: æœªæå–åˆ°ç« èŠ‚ç»“æ„")
        
        print(f"  âœ… å…ƒæ•°æ®æå–å®Œæˆ")
        print(f"     - æ ‡é¢˜: {result.get('title', 'N/A')[:50]}...")
        print(f"     - ä½œè€…æ•°: {len(result.get('authors', []))}")
        print(f"     - ç« èŠ‚æ•°: {len(result.get('sections', []))}")
        
        return result
        
    except Exception as e:
        print(f"âŒ å…ƒæ•°æ®æå–å¤±è´¥: {e}")
        raise


def extract_detailed_sections(markdown_text: str,
                              section_names: Optional[List[str]] = None) -> Dict[str, str]:
    """
    æå–ç‰¹å®šç« èŠ‚çš„è¯¦ç»†å†…å®¹
    
    Args:
        markdown_text: è®ºæ–‡Markdownæ–‡æœ¬
        section_names: è¦æå–çš„ç« èŠ‚åç§°åˆ—è¡¨ï¼Œé»˜è®¤ä¸ºå¸¸è§ç« èŠ‚
    
    Returns:
        {
            "Introduction": "å®Œæ•´å†…å®¹...",
            "Method": "å®Œæ•´å†…å®¹...",
            ...
        }
    """
    if section_names is None:
        section_names = [
            "Introduction",
            "Related Work",
            "Method", "Methodology",
            "Experiments", "Results",
            "Conclusion",
            "Discussion"
        ]
    
    api = DeepSeekAPI()
    
    # ç”±äºæ–‡æœ¬å¯èƒ½å¾ˆé•¿ï¼Œè¿™é‡Œä½¿ç”¨ç®€å•çš„æ–‡æœ¬åˆ†å‰²æ–¹æ³•
    # å®é™…åº”ç”¨ä¸­å¯èƒ½éœ€è¦æ›´å¤æ‚çš„ç« èŠ‚è¯†åˆ«
    
    sections_content = {}
    
    for section_name in section_names:
        prompt = f"""
è¯·ä»ä»¥ä¸‹è®ºæ–‡ä¸­æå–"{section_name}"ç« èŠ‚çš„å®Œæ•´å†…å®¹ã€‚

å¦‚æœæ‰¾åˆ°è¯¥ç« èŠ‚ï¼Œè¯·è¿”å›JSONæ ¼å¼ï¼š
{{"section_name": "{section_name}", "content": "å®Œæ•´å†…å®¹", "found": true}}

å¦‚æœæœªæ‰¾åˆ°è¯¥ç« èŠ‚ï¼Œè¯·è¿”å›ï¼š
{{"section_name": "{section_name}", "content": "", "found": false}}

è®ºæ–‡å†…å®¹ï¼š
{markdown_text[:30000]}  # é™åˆ¶é•¿åº¦

è¯·ä¸¥æ ¼è¿”å›JSONæ ¼å¼ã€‚
"""
        
        try:
            result = api.simple_ask_json(prompt, temperature=0.1)
            if result.get('found'):
                sections_content[section_name] = result.get('content', '')
        except:
            continue
    
    return sections_content


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ç”¨æ³•: python metadata_extractor.py <markdown_file>")
        sys.exit(1)
    
    markdown_file = sys.argv[1]
    
    print("=" * 60)
    print("å…ƒæ•°æ®æå–æµ‹è¯•")
    print("=" * 60)
    
    # è¯»å–markdown
    try:
        with open(markdown_file, 'r', encoding='utf-8') as f:
            markdown_text = f.read()
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        sys.exit(1)
    
    # æå–å…ƒæ•°æ®
    try:
        metadata = extract_metadata(markdown_text)
        
        print("\n" + "=" * 60)
        print("æå–ç»“æœ")
        print("=" * 60)
        print(json.dumps(metadata, ensure_ascii=False, indent=2))
        
        # ä¿å­˜ç»“æœ
        output_file = markdown_file.replace('.md', '_metadata.json')
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(metadata, f, ensure_ascii=False, indent=2)
        
        print(f"\nâœ… ç»“æœå·²ä¿å­˜è‡³: {output_file}")
        
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
